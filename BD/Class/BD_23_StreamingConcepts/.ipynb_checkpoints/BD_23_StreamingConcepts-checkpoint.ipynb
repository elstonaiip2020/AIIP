{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - dealing with JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll take a look at a publically available data stream, made available by New York's bike sharing company Citi Bike (https://www.citibikenyc.com/system-data), and see what it takes to process the data into something we can work with. \n",
    "\n",
    "In this case, we're told the data follows the GBFS standard (https://github.com/NABSA/gbfs/blob/master/gbfs.md), which is based on JSON. To read JSON, we use the `json` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a quick example of using the json library to read a JSON string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = '{\"one\" : \"The number 1\", \"two\" : 2, \"three\" : true}'\n",
    "j = json.loads(json_string)\n",
    "print(j['two'])\n",
    "print(j['three'])\n",
    "print(type(j)) #print(j['two'])\n",
    "j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "\n",
    "If you go to the 'data feed' linked from the Citi Bike website (http://gbfs.citibikenyc.com/gbfs/gbfs.json) you'll see some json, rendered as text by your browser:\n",
    "\n",
    "{\"last_updated\":1526323312,\"ttl\":10,\"data\":{\"en\":{\"feeds\"......."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking out the docs (https://github.com/NABSA/gbfs/blob/master/gbfs.md), we see that this is a list of files. Of interest to us is the stations file. We want to observe how many bikes are available at different stations over time. Here's the json: http://www.citibikenyc.com/stations/json\n",
    "\n",
    "We need to process this a bit. Here, we'll use the urllib linrary to get the json, and then call json.loads() to convert into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "json_string = urllib.request.urlopen('http://www.citibikenyc.com/stations/json').read()\n",
    "stations = json.loads(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to see what we get. Hard to tell what it looks like!\n",
    "# print(stations)\n",
    "stations.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at stations and see if you can figure out what's going on. stations.keys() shows that this is a dictionary with two keys: executionTime and stationBeanList. stationBeanList is what we're interested in. A list of dictionaries (which were JSON objects), each representing a station. Here's the first one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations['stationBeanList'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's throw this data into a dataframe so we can take a better look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(stations['stationBeanList'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go! How many bikes are available on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average value of the 'availableBikes column\n",
    "df['availableBikes'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can repeat the steps to pull the latest available data from the URL (it updates every minute) and see what has changed. Remember, it might be night time in New York, in which case this might be a very boring exercise..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = json.loads(urllib.request.urlopen('http://www.citibikenyc.com/stations/json').read()) # Get new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(pd.DataFrame(stations['stationBeanList'])) # Add the data to our existing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['stAddress1'] == 'W 52 St & 11 Ave'] # Look at one particular station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two records for each station. \n",
    "\n",
    "This is a very slow data stream, and we have to actively go and fetch the data each time. However, you can already see some hypothetical use cases. For example, can you write code to display a list of the emptiest stations, updated every minute? Or print a warning if any station has less than 3 bikes? What about making a plot showing the number of bikes at a given station over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to play around with this for practice, try to implement one of the ideas above.\n",
    "\n",
    "To see an example of how someone else processed this data, check out https://gist.github.com/matmoody/531456524169716929947f39fb043793"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 - Simulated Streaming Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll write code to simulate a common streaming data scenarion - processing information as it arrives. We simulate a stream of data arriving with a for loop. Each time the loop runs, we create a new, imaginary piece of data, which is then processed. We also create some variables outside of the loop - these are state variables to keep track of things like the average or the total number of records received. The last ten records are kept in an array - our moving window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math, random\n",
    "\n",
    "window = [] # The moving window\n",
    "average_val = 0\n",
    "window_sd = 0\n",
    "window_av = 0\n",
    "n_records = 0\n",
    "db = pd.DataFrame(columns=['Time', 'Value', 'Average_val', 'sd'])\n",
    "\n",
    "# def process(record):\n",
    "\n",
    "for i in range(100):\n",
    "    # Here is our simulated data: a single value, and a 'time of arrival' (here just i)\n",
    "    fakeval = math.sin(2*math.pi*i/70) +4 + random.random()\n",
    "    arrival_time = i\n",
    "    \n",
    "    # And here is where we process it\n",
    "    n_records += 1 # Update the counter\n",
    "    average_val = average_val*0.75 + fakeval*0.25 # Update the average (exponantial averaging)\n",
    "    window.append(fakeval) # Add the record to our moving window\n",
    "    if len(window)>10: # Keep the window size from growing beyond 10:\n",
    "        del(window[0]) # If the window is >10 items, delete the oldest\n",
    "    window_sd = np.std(window) # Calculate the standard deviation of the ten items in the window\n",
    "    window_av = np.mean(window) # Calculate the mean of the last ten readings\n",
    "    \n",
    "    # And add the simulated reading and calculated values to a database (or in this case just a pandas DataFrame)\n",
    "    db = pd.concat([db, pd.DataFrame([{'Time': i, 'Value':fakeval, 'Average_val':average_val, 'sd':window_sd, 'av':window_av}])], ignore_index=True, sort=True)\n",
    "    # At this stage, we could trigger events if, for example, the average of the last ten readings was too high, or the reading anomalous...\n",
    "\n",
    "# we've processed 100 incoming records and stored the results. Each row of the dataframe contains the values we'd show at a given time\n",
    "db.head() # The first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results, including the window average and sd\n",
    "%matplotlib inline\n",
    "db.plot(x='Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows a lot of things at once. Use the following template to do the following:\n",
    "- As records 'arrive', print out the Value and the average to date (without storing all records)\n",
    "- Create a sliding window of size 3. As records arrive, print out the value and the mean of the sliding window\n",
    "- As records arrive, print an alert when the value is above 5.1. \n",
    "- As records arrive, print an alert when the vlaue has been above 4.8 for three consecutive readings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create any variables you'll need here\n",
    "\n",
    "for i in range(100):\n",
    "    # Here is our simulated data: a single value, and a 'time of arrival' (here just i)\n",
    "    fakeval = math.sin(2*math.pi*i/70) +4 + random.random()\n",
    "    arrival_time = i\n",
    "    \n",
    "    # Your code\n",
    "    #print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
