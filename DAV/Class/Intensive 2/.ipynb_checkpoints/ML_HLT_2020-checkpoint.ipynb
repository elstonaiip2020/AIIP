{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HLT Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise is split into three parts. In the first, we'll load and examine two datasets with associated classification problems. In the second section, we'll try logistic regression and then compare it's performance with some other models. Finally, in section 3, we'll try our new techniques on data from a Zindi competition, to see how the models performace compares with the top entries.\n",
    "\n",
    "Deliverables are marked in bold and numbered - please make sure you answer all questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the libraries we'll use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn import model_selection, datasets, linear_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1 - Digits\n",
    "\n",
    "This is somewhat of a 'hello world' of machine learning - classifying handwritten digits.\n",
    "\n",
    "There is a digits dataset built in to sklearn, so we can access it easily (sklearn.datasets.load_digits())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X contains sets of features, and y contains the corresponding class. In this case, the features are the pixel values in an 8x8 image of a hand-written number. Let's look at the first digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_digits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_digits[0] # The class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, the first digit is a zero. Let's plot it and see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_digits[0].reshape(8, 8), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: plot 3 more images. Do the tags (y values) match what you think the numbers look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer task 1 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use the arrays of X and y as they are for model building, but we may as well put them into a pandas dataframe to get in some more practice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_df = pd.DataFrame(X_digits)\n",
    "digits_df['class'] = y_digits\n",
    "digits_df.head() # 64 pixel values then the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step, we'll split the data into test and train sets - the test set will be used to evaluate the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_train, digits_test = model_selection.train_test_split(digits_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2 - Robot Collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('collisions.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classses are mapped with the following: classes = {'normal':0, 'collision':1, 'obstruction':2, 'fr_collision':3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read about the dataset from which these values were derived here: https://archive.ics.uci.edu/ml/datasets/Robot+Execution+Failures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at how the classes differ. \n",
    "data.hist(by='class', column='t3') # Try f1, f2, f3, t1, t2, t3\n",
    "# Add sharex=True to the function above - does this make the differences clearer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Compare the mean values for force 1 ('f1') for normal operation (class 0) vs a collision (class 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer task 2 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the final step in getting this data ready is to split it into training data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_train, robot_test = model_selection.train_test_split(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the data loaded into training and test sets. Now we'll fit a logistic regression model and use this as a baseline for further investigations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression(solver='liblinear', multi_class='auto') # Parameters to avoid warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = robot_train[['f1', 'f2', 'f3', 't1', 't2', 't3']] # The input columns\n",
    "y = robot_train['class'] # Must be an integer\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X, y) # Score on the TRAINING data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And to score on the test data\n",
    "XT = robot_test[['f1', 'f2', 'f3', 't1', 't2', 't3']]\n",
    "yT = robot_test['class']\n",
    "model.score(XT, yT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, but tighter code - you can copy and paste this for quick tests\n",
    "model = linear_model.LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "model.fit(robot_train[robot_train.columns[:-2]], robot_train['class'])\n",
    "print(\"Training score: \"+str(model.score(robot_train[robot_train.columns[:-2]], robot_train['class'])))\n",
    "print(\"Test score:     \"+str(model.score(robot_test[robot_test.columns[:-2]], robot_test['class'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And for digits:\n",
    "model = linear_model.LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "model.fit(digits_train[digits_train.columns[:-1]], digits_train['class'])\n",
    "print(\"Training score: \"+str(model.score(digits_train[digits_train.columns[:-1]], digits_train['class'])))\n",
    "print(\"Test score:     \"+str(model.score(digits_test[digits_test.columns[:-1]], digits_test['class'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Note the scores, then re-run from the start to get a different test-train split. Have the scores changed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got data, and we've seen how to fit a model to that data and score it on a test dataset. Now for the fun part, and the main section of this exercise - trying out different models!\n",
    "\n",
    "Check out how many different supervised learning models are available in scikit-learn: http://scikit-learn.org/stable/supervised_learning.html\n",
    "\n",
    "We're going to use our datasets that we've prepared to try out different models. I'll list some common classifiers for you to try, and hint at what parameters you could change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "#..... Look at the docs and see if you can find one extra one! Make sure it's a classification algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Try out at least ten different models, and pick your best!\n",
    "\n",
    "These should include at least 3 different types of models, and some of the same type with different parameters.\n",
    "Be sure to show scores or otherwise justify your choice of 'best model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Jam (Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data comes from a competition on Zindi. The training data was initially provided as individual ticket sales. You can check out the details <a href=https://zindi.africa/>on Zindi</a> (under 'Competitions').\n",
    "\n",
    "The goal is to predict ticket sales for each ride (identified by ride ID), so I grouped by the 'ride ID' column and counted the tickets for each (.count()). The code keeps the other columns of interest.\n",
    "\n",
    "\n",
    "`train = df.groupby(['ride_id', 'travel_date', 'travel_time',  'travel_from', 'car_type', 'max_capacity']).size().reset_index(name='Count')`\n",
    "\n",
    "For convenience, the data is now in two csv files, 'sales.csv' for model development and 'test_questions.csv' to make predictions on. Each has the same format. For testing, split 'train' further to validate your models. To see how you'd score on Zindi you'll have to sign up for an account and upload your predictions. This example shows creating the predictions file in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sales.csv', parse_dates = ['travel_date'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different feature engineering tricks.\n",
    "# For this example, we just convert the 'travel_from' column into dumy vars and fit a model from that\n",
    "data = pd.get_dummies(df, columns=['travel_from'])\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define our input columns\n",
    "in_cols = data.columns.values.tolist()\n",
    "in_cols.remove('Count')\n",
    "in_cols.remove('ride_id')\n",
    "in_cols.remove('travel_time')\n",
    "in_cols.remove('travel_date')\n",
    "in_cols.remove('car_type')\n",
    "\n",
    "# Inputs and desired output (count)\n",
    "X = data[in_cols]\n",
    "y = data['Count']\n",
    "\n",
    "# Split into test/train (the provided test set has no answers, so we need to make our own test set for model comparison)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "regr = DecisionTreeRegressor(max_depth=3)\n",
    "regr.fit(X_train, y_train)\n",
    "print(regr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot y_test (the correct values) against regr.predict(X_test) (the predictions) - do they match well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Try out at least three models, and add at least one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying different models and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To submit on Zindi, we need to make predictions for the test set. We do the same to the test data, make predictions and store these in a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "test = pd.read_csv('test_questions.csv', parse_dates = ['travel_date'])\n",
    "test.head() # Same as 'sales' but missing the 'Count' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the same features as you dod for the training data:\n",
    "test_data = pd.get_dummies(test, columns=['travel_from']) # Creating our dummy variables as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column with the predictions\n",
    "test['Count'] = regr.predict(test_data[in_cols]) # Modify if you've added columns etc\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as csv - can be uploaded to Zindi (note - just ride_id and Count coluns are included)\n",
    "test[['ride_id', 'Count']].to_csv('preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
